{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Quiz_Q3.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahmutgemici/Midterm1/blob/main/Quiz_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j0CPvxmphT0m"
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D,concatenate,AveragePooling2D, Dropout\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.layers import Input\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gkTo72VohT0p",
        "outputId": "b3ba328f-b9e9-49cd-f9f0-56e5d160c75e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "# Get the data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Get the data ready\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xjnEfapOhT0s"
      },
      "source": [
        "# # Create imput\n",
        "# input_img = Input(shape = (32, 32, 3))\n",
        "\n",
        "\n",
        "\n",
        "# # Create Volumes for the Inception module\n",
        "# volume_1 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)\n",
        "\n",
        "# volume_2 = Conv2D(96, (1,1), padding='same', activation='relu')(input_img)\n",
        "# volume_2 = Conv2D(128, (3,3), padding='same', activation='relu')(volume_2)\n",
        "\n",
        "# volume_3 = Conv2D(16, (1,1), padding='same', activation='relu')(input_img)\n",
        "# volume_3 = Conv2D(32, (5,5), padding='same', activation='relu')(volume_3)\n",
        "\n",
        "# volume_4 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "# volume_4 = Conv2D(32, (1,1), padding='same', activation='relu')(volume_4)\n",
        "\n",
        "# # Concatenate all volumes of the Inception module\n",
        "# inception_module = keras.layers.concatenate([volume_1, volume_2, volume_3,\n",
        "#                                              volume_4], axis = 3)\n",
        "# output = Flatten()(inception_module)\n",
        "# out    = Dense(10, activation='softmax')(output)\n",
        "\n",
        "\n",
        "# model = Model(inputs = input_img, outputs = out)\n",
        "# print(model.summary())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y1gv_WEghT0u",
        "outputId": "b68973c3-e579-4830-b03e-a34b5c92e50b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create imput\n",
        "input_img = Input(shape = (32, 32, 3))\n",
        "\n",
        "\n",
        "\n",
        "# Create Volumes for the Inception module\n",
        "volume_1 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)\n",
        "\n",
        "volume_2 = Conv2D(96, (1,1), padding='same', activation='relu')(input_img)\n",
        "volume_2 = Conv2D(128, (3,3), padding='same', activation='relu')(volume_2)\n",
        "\n",
        "volume_3 = Conv2D(16, (1,1), padding='same', activation='relu')(input_img)\n",
        "volume_3 = Conv2D(32, (5,5), padding='same', activation='relu')(volume_3)\n",
        "\n",
        "volume_4 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "volume_4 = Conv2D(32, (1,1), padding='same', activation='relu')(volume_4)\n",
        "\n",
        "# Concatenate all volumes of the Inception module\n",
        "inception_module = keras.layers.concatenate([volume_1, volume_2, volume_3,\n",
        "                                             volume_4], axis = 3)\n",
        "\n",
        "######\n",
        "volume_5 = Conv2D(128, (1,1), padding='same', activation='relu')(inception_module)\n",
        "\n",
        "volume_6 = Conv2D(128, (1,1), padding='same', activation='relu')(inception_module)\n",
        "volume_6 = Conv2D(196, (3,3), padding='same', activation='relu')(volume_6)\n",
        "\n",
        "volume_7 = Conv2D(32, (1,1), padding='same', activation='relu')(inception_module)\n",
        "volume_7 = Conv2D(96, (5,5), padding='same', activation='relu')(volume_7)\n",
        "\n",
        "\n",
        "volume_8 = MaxPooling2D((3,3), strides=(1,1), padding='same')(inception_module)\n",
        "volume_8 = Conv2D(64, (1,1), padding='same', activation='relu')(volume_8)\n",
        "\n",
        "inception_module = keras.layers.concatenate([volume_5, volume_6, volume_7,\n",
        "                                             volume_8], axis = 3)\n",
        "\n",
        "#####\n",
        "volume_9=MaxPooling2D((3,3), strides=(1,1), padding='same')(inception_module)\n",
        "####\n",
        "\n",
        "volume_10 = Conv2D(192, (1,1), padding='same', activation='relu')(volume_9)\n",
        "\n",
        "volume_11 = Conv2D(96, (1,1), padding='same', activation='relu')(volume_9)\n",
        "volume_11 = Conv2D(208, (3,3), padding='same', activation='relu')(volume_11)\n",
        "\n",
        "volume_12 = Conv2D(16, (1,1), padding='same', activation='relu')(volume_9)\n",
        "volume_12= Conv2D(48, (5,5), padding='same', activation='relu')(volume_12)\n",
        "\n",
        "\n",
        "volume_13 = MaxPooling2D((3,3), strides=(1,1), padding='same')(volume_9)\n",
        "volume_13 = Conv2D(64, (1,1), padding='same', activation='relu')(volume_13)\n",
        "\n",
        "inception_module = keras.layers.concatenate([volume_10, volume_11, volume_12,\n",
        "                                             volume_13], axis = 3)\n",
        "\n",
        "# ####################\n",
        "volume_14 = AveragePooling2D((5, 5), strides=3)(inception_module)\n",
        "volume_14 = Conv2D(128, (1, 1), padding='same', activation='relu')(volume_14)\n",
        "volume_14 = Flatten()(volume_14)\n",
        "volume_14 = Dense(1024, activation='relu')(volume_14)\n",
        "volume_14 = Dropout(0.7)(volume_14)\n",
        "volume_14 = Dense(10, activation='softmax', name='auxilliary_output_1')(volume_14)\n",
        "\n",
        "# ###############\n",
        "\n",
        "\n",
        "volume_15 = Conv2D(160, (1,1), padding='same', activation='relu')(inception_module)\n",
        "\n",
        "volume_16 = Conv2D(112, (1,1), padding='same', activation='relu')(inception_module)\n",
        "volume_16 = Conv2D(224, (3,3), padding='same', activation='relu')(volume_16)\n",
        "\n",
        "volume_17 = Conv2D(24, (1,1), padding='same', activation='relu')(inception_module)\n",
        "volume_17= Conv2D(64, (5,5), padding='same', activation='relu')(volume_17)\n",
        "\n",
        "\n",
        "volume_18 = MaxPooling2D((3,3), strides=(1,1), padding='same')(inception_module)\n",
        "volume_18 = Conv2D(64, (1,1), padding='same', activation='relu')(volume_18)\n",
        "\n",
        "inception_module = keras.layers.concatenate([volume_15, volume_16, volume_17,\n",
        "                                             volume_18], axis = 3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "output = Flatten()(inception_module)\n",
        "out    = Dense(10, activation='softmax')(output)\n",
        "\n",
        "\n",
        "model = Model(inputs = input_img, outputs = out)\n",
        "print(model.summary());"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 96)   384         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   64          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 128)  110720      conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   12832       conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   128         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 256)  0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  32896       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 32)   8224        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 256)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 128)  32896       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 196)  225988      conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 96)   76896       conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 64)   16448       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 484)  0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 484)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 96)   46560       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   7760        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 484)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 192)  93120       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 208)  179920      conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 48)   19248       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 64)   31040       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 512)  0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 112)  57456       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 24)   12312       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 512)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 160)  82080       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 224)  226016      conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 64)   38464       conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 64)   32832       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 512)  0           conv2d_19[0][0]                  \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 524288)       0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           5242890     flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,587,430\n",
            "Trainable params: 6,587,430\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gpTeUdjJhT0x",
        "outputId": "c07a57c1-a831-4d7f-f508-e0152f2a9791",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=512)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 2/98 [..............................] - ETA: 38s - loss: 7.3206 - accuracy: 0.0928WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2593s vs `on_train_batch_end` time: 0.5313s). Check your callbacks.\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 1.8490 - accuracy: 0.3823 - val_loss: 1.3709 - val_accuracy: 0.5137\n",
            "Epoch 2/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 1.2517 - accuracy: 0.5561 - val_loss: 1.1411 - val_accuracy: 0.5920\n",
            "Epoch 3/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 1.0168 - accuracy: 0.6422 - val_loss: 0.9585 - val_accuracy: 0.6644\n",
            "Epoch 4/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.8511 - accuracy: 0.7029 - val_loss: 0.9150 - val_accuracy: 0.6830\n",
            "Epoch 5/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.7290 - accuracy: 0.7481 - val_loss: 0.8350 - val_accuracy: 0.7094\n",
            "Epoch 6/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.6243 - accuracy: 0.7840 - val_loss: 0.7988 - val_accuracy: 0.7263\n",
            "Epoch 7/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.5167 - accuracy: 0.8221 - val_loss: 0.7846 - val_accuracy: 0.7412\n",
            "Epoch 8/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.4137 - accuracy: 0.8581 - val_loss: 0.8383 - val_accuracy: 0.7341\n",
            "Epoch 9/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.3190 - accuracy: 0.8897 - val_loss: 0.9159 - val_accuracy: 0.7254\n",
            "Epoch 10/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.2351 - accuracy: 0.9200 - val_loss: 1.0563 - val_accuracy: 0.7233\n",
            "Epoch 11/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.1594 - accuracy: 0.9444 - val_loss: 1.1428 - val_accuracy: 0.7339\n",
            "Epoch 12/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.1062 - accuracy: 0.9637 - val_loss: 1.3225 - val_accuracy: 0.7203\n",
            "Epoch 13/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0785 - accuracy: 0.9735 - val_loss: 1.4416 - val_accuracy: 0.7253\n",
            "Epoch 14/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0553 - accuracy: 0.9820 - val_loss: 1.6807 - val_accuracy: 0.7162\n",
            "Epoch 15/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0608 - accuracy: 0.9788 - val_loss: 1.7049 - val_accuracy: 0.7223\n",
            "Epoch 16/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 1.7826 - val_accuracy: 0.7222\n",
            "Epoch 17/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0499 - accuracy: 0.9827 - val_loss: 1.8647 - val_accuracy: 0.7204\n",
            "Epoch 18/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0477 - accuracy: 0.9835 - val_loss: 1.8919 - val_accuracy: 0.7147\n",
            "Epoch 19/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 2.0261 - val_accuracy: 0.7172\n",
            "Epoch 20/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0350 - accuracy: 0.9880 - val_loss: 1.9934 - val_accuracy: 0.7246\n",
            "Epoch 21/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 1.9665 - val_accuracy: 0.7156\n",
            "Epoch 22/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 2.2423 - val_accuracy: 0.7113\n",
            "Epoch 23/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 2.1404 - val_accuracy: 0.7170\n",
            "Epoch 24/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 2.2029 - val_accuracy: 0.7223\n",
            "Epoch 25/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 2.3765 - val_accuracy: 0.7216\n",
            "Epoch 26/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 2.1199 - val_accuracy: 0.7278\n",
            "Epoch 27/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0330 - accuracy: 0.9885 - val_loss: 2.1831 - val_accuracy: 0.7115\n",
            "Epoch 28/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0336 - accuracy: 0.9880 - val_loss: 2.3563 - val_accuracy: 0.7170\n",
            "Epoch 29/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 2.3794 - val_accuracy: 0.7155\n",
            "Epoch 30/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 2.3458 - val_accuracy: 0.7278\n",
            "Epoch 31/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 2.3501 - val_accuracy: 0.7232\n",
            "Epoch 32/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0300 - accuracy: 0.9897 - val_loss: 2.3077 - val_accuracy: 0.7124\n",
            "Epoch 33/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 2.4574 - val_accuracy: 0.7098\n",
            "Epoch 34/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0332 - accuracy: 0.9886 - val_loss: 2.3072 - val_accuracy: 0.7192\n",
            "Epoch 35/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 2.4438 - val_accuracy: 0.7136\n",
            "Epoch 36/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 2.4624 - val_accuracy: 0.7172\n",
            "Epoch 37/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 2.3471 - val_accuracy: 0.7245\n",
            "Epoch 38/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 2.4020 - val_accuracy: 0.7195\n",
            "Epoch 39/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 2.4449 - val_accuracy: 0.7128\n",
            "Epoch 40/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 2.5638 - val_accuracy: 0.7174\n",
            "Epoch 41/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 2.4985 - val_accuracy: 0.7142\n",
            "Epoch 42/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 2.6742 - val_accuracy: 0.7184\n",
            "Epoch 43/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 2.5408 - val_accuracy: 0.7280\n",
            "Epoch 44/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 2.6796 - val_accuracy: 0.7240\n",
            "Epoch 45/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 2.6273 - val_accuracy: 0.7072\n",
            "Epoch 46/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0265 - accuracy: 0.9907 - val_loss: 2.4272 - val_accuracy: 0.7319\n",
            "Epoch 47/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 2.5549 - val_accuracy: 0.7273\n",
            "Epoch 48/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 2.6623 - val_accuracy: 0.7262\n",
            "Epoch 49/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 2.6807 - val_accuracy: 0.7224\n",
            "Epoch 50/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 2.7311 - val_accuracy: 0.7177\n",
            "Epoch 51/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 2.6654 - val_accuracy: 0.7195\n",
            "Epoch 52/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 2.5683 - val_accuracy: 0.7176\n",
            "Epoch 53/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 2.7786 - val_accuracy: 0.7180\n",
            "Epoch 54/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 2.9052 - val_accuracy: 0.7143\n",
            "Epoch 55/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 3.0741 - val_accuracy: 0.7027\n",
            "Epoch 56/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 2.9126 - val_accuracy: 0.7131\n",
            "Epoch 57/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 2.8665 - val_accuracy: 0.7086\n",
            "Epoch 58/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 2.6926 - val_accuracy: 0.7077\n",
            "Epoch 59/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 2.7564 - val_accuracy: 0.7116\n",
            "Epoch 60/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 2.9207 - val_accuracy: 0.7240\n",
            "Epoch 61/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 2.7275 - val_accuracy: 0.7136\n",
            "Epoch 62/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 2.7666 - val_accuracy: 0.7222\n",
            "Epoch 63/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 2.7955 - val_accuracy: 0.7231\n",
            "Epoch 64/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 2.8678 - val_accuracy: 0.7193\n",
            "Epoch 65/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 3.3133 - val_accuracy: 0.7088\n",
            "Epoch 66/100\n",
            "98/98 [==============================] - 82s 835ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 3.0419 - val_accuracy: 0.7133\n",
            "Epoch 67/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 3.1109 - val_accuracy: 0.7147\n",
            "Epoch 68/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 3.2181 - val_accuracy: 0.7200\n",
            "Epoch 69/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 2.9870 - val_accuracy: 0.7125\n",
            "Epoch 70/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 3.0061 - val_accuracy: 0.7047\n",
            "Epoch 71/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 3.0552 - val_accuracy: 0.7057\n",
            "Epoch 72/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 2.9758 - val_accuracy: 0.7196\n",
            "Epoch 73/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 2.8728 - val_accuracy: 0.7218\n",
            "Epoch 74/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 3.2364 - val_accuracy: 0.7140\n",
            "Epoch 75/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 3.1739 - val_accuracy: 0.7123\n",
            "Epoch 76/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 3.1467 - val_accuracy: 0.7100\n",
            "Epoch 77/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 2.8927 - val_accuracy: 0.7209\n",
            "Epoch 78/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 3.1195 - val_accuracy: 0.7229\n",
            "Epoch 79/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 3.1410 - val_accuracy: 0.7133\n",
            "Epoch 80/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 3.1264 - val_accuracy: 0.7098\n",
            "Epoch 81/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 3.1566 - val_accuracy: 0.7188\n",
            "Epoch 82/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 3.2320 - val_accuracy: 0.7183\n",
            "Epoch 83/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 3.2479 - val_accuracy: 0.7190\n",
            "Epoch 84/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 3.4071 - val_accuracy: 0.7256\n",
            "Epoch 85/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 3.1650 - val_accuracy: 0.7159\n",
            "Epoch 86/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 3.3564 - val_accuracy: 0.7200\n",
            "Epoch 87/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 3.4631 - val_accuracy: 0.7159\n",
            "Epoch 88/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 3.2640 - val_accuracy: 0.7208\n",
            "Epoch 89/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 3.3026 - val_accuracy: 0.7102\n",
            "Epoch 90/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 3.1132 - val_accuracy: 0.7245\n",
            "Epoch 91/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 3.1408 - val_accuracy: 0.7292\n",
            "Epoch 92/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 3.4652 - val_accuracy: 0.7189\n",
            "Epoch 93/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 3.2431 - val_accuracy: 0.7288\n",
            "Epoch 94/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 3.2453 - val_accuracy: 0.7227\n",
            "Epoch 95/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 3.7060 - val_accuracy: 0.7167\n",
            "Epoch 96/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 3.5158 - val_accuracy: 0.7123\n",
            "Epoch 97/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 3.4896 - val_accuracy: 0.7218\n",
            "Epoch 98/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 3.4045 - val_accuracy: 0.7078\n",
            "Epoch 99/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 3.2708 - val_accuracy: 0.7171\n",
            "Epoch 100/100\n",
            "98/98 [==============================] - 82s 834ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 3.4195 - val_accuracy: 0.7167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NjokjB2ghT0z",
        "outputId": "c8a2699d-c7c8-4ca5-cda1-98fafcb95000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 71.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T8pRis0HhT01"
      },
      "source": [
        "model.save('epoch25.h5')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEWGjT0qvF8S"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}